{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tresure Machine Learning Model Development","metadata":{"id":"_hNM6yJjqstz"}},{"cell_type":"markdown","source":"## External Module and Library Dependancies","metadata":{"id":"MSilQYxlvISp"}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"id":"gqcj4LfXvEAi","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extract data","metadata":{"id":"TjZkARsXqxqC"}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/Tresure-Bangkit2023/ml-tresure/main/data/user.csv\n!wget https://raw.githubusercontent.com/Tresure-Bangkit2023/ml-tresure/main/data/tourism_with_id.csv\n!wget https://raw.githubusercontent.com/Tresure-Bangkit2023/ml-tresure/main/data/tourism_rating.csv","metadata":{"id":"TE0EiW-HwyxR","outputId":"c6467c66-3110-4def-94ad-145030a68443","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#\n# Read CSV and save as Pandas DataFrame\n#\ndf_user             = pd.read_csv('user.csv')\ndf_tourism_with_id  = pd.read_csv('tourism_with_id.csv')\ndf_tourism_rating   = pd.read_csv('tourism_rating.csv')","metadata":{"id":"mMtDGu5GzNO3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transform data","metadata":{"id":"vVi7sXROuMeF"}},{"cell_type":"code","source":"# Inspect df_user DataFrame\ndf_user.head()","metadata":{"id":"kNZAqNnPuJ-9","outputId":"26e024db-22e6-4e16-a4af-98d40ba9ea15","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspect df_tourism_with_id DataFrame\ndf_tourism_with_id.head()","metadata":{"id":"IS5chUns9XYs","outputId":"4d5099bc-461b-4cb5-caf5-57b7fb23d2d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspect df_tourism_rating DataFrame\ndf_tourism_rating.head()","metadata":{"id":"wyEWsSul933G","outputId":"c0659263-e815-4c1b-c5ca-f36a783bb722","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### User DataFrame","metadata":{"id":"Ls8SidAR04LJ"}},{"cell_type":"code","source":"df_user.info()","metadata":{"id":"0DFu55l_0_pd","outputId":"9f33651a-b306-44c2-d5a0-df4a84f00710","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_user.describe()","metadata":{"id":"EqrnaQVu2xWG","outputId":"19baca60-6c8e-4a0c-f0c0-f8f714ea83cd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is the user DataFrame numeric values' details. We have the **average age** for user in this dataset is **28.7** ranging from 18 to 40.","metadata":{"id":"BhE5WVtT3Btf"}},{"cell_type":"markdown","source":"### Tourism with ID DataFrame","metadata":{"id":"9phCQghT2st7"}},{"cell_type":"code","source":"df_tourism_with_id.info()","metadata":{"id":"BZOhNeDM28uN","outputId":"96d75e02-6c0b-4eda-f4ee-484786882c38","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tourism_with_id.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 10 columns with 437 non-null values. However, we have two unknown columns that have 0 value and a repeated index column respectively. We can drop those last 2 column. And we also have **Time_Minutes** column that only have 205 non-null values and we consider it's not helping in any chance. \n\nWe also want to drop the **Description**, **Coordinate**, **Lat**, and **Long** columns because they are not going to be used in the machine learning model.","metadata":{"id":"c_p9hRB233W2"}},{"cell_type":"code","source":"df_tourism_with_id = df_tourism_with_id.drop(columns = ['Description',\n                                                        'Time_Minutes',\n                                                        'Coordinate',\n                                                        'Lat',\n                                                        'Long',\n                                                        'Unnamed: 11',\n                                                        'Unnamed: 12',])\ndf_tourism_with_id.info()","metadata":{"id":"RXe2O3F34PCU","outputId":"016303f9-4c84-4167-ea6a-04674c503d45","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have only 6 columns to be fed into the machine learning model. Let's inspect the first 5 entries.","metadata":{"id":"hZmo1Kux7N_T"}},{"cell_type":"code","source":"df_tourism_with_id.head()","metadata":{"id":"hbjkeDsX7NuG","outputId":"57704eb5-5eef-4e71-a27a-9f0a5445a72b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tourism_with_id.describe()","metadata":{"id":"3lRSda1q7b-q","outputId":"fbc5f719-ec12-4417-908d-88e7da5afa6a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is the tourism_with_id DataFrame numeric values' details. We have  **average price** of Rp24,652 ranging from Rp0 to Rp900,000 and **average rating** of 4.44 ranging from 3.4 to 5.0","metadata":{"id":"O06KBbGp7e53"}},{"cell_type":"markdown","source":"### Tourism Rating DataFrame","metadata":{"id":"pCdKIG2D7CNC"}},{"cell_type":"code","source":"df_tourism_rating.info()","metadata":{"id":"jaT_WgJJ8Co_","outputId":"59a09e30-902c-4aca-d63e-6efc333ebf3b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, we have 3 columns and 10000 non-null entries comprising the user and the place_id with the corresponding ratings.","metadata":{"id":"W5K-zfzL8S_b"}},{"cell_type":"code","source":"df_tourism_rating.head()","metadata":{"id":"R9aiAsvs8Scb","outputId":"f8cf0164-a2cc-489c-8217-b0afa804841b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tourism_rating.describe()","metadata":{"id":"DUCLQoqjff4h","outputId":"d48532fd-b495-4e7b-ecbb-29384e051fd0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, normalize the ratings column using MinMax Normalization\n","metadata":{}},{"cell_type":"code","source":"df_tourism_rating['Place_Ratings'] = MinMaxScaler().fit_transform(\n    np.array(df_tourism_rating['Place_Ratings']).reshape(-1,1)\n)\n\ndf_tourism_rating.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling\n","metadata":{"id":"TZ25513mw7zB"}},{"cell_type":"code","source":"df = df_tourism_rating\n\n# Train Test Split\nX = df.drop(columns = ['Place_Ratings'])\ny = df['Place_Ratings']\n\nx_train, x_rem, y_train, y_rem = train_test_split(X, y, test_size = .3, random_state = 1)\n\nx_val, x_test, y_val, y_test = train_test_split(x_rem, y_rem, test_size = .5, random_state = 1)","metadata":{"id":"N5xBFIK_6Bh8","outputId":"b0e52f9d-cd3e-4695-b462-1fae27227d3e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(x_val.shape)\nprint(x_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mendapatkan jumlah user\nnum_users = len(df_user)\nprint(num_users)\n \n# Mendapatkan jumlah places\nnum_places = len(df_tourism_with_id)\nprint(num_places)","metadata":{"id":"8eoxoiQX5u3l","outputId":"c080b9b2-b837-480f-c308-43ec1c17d292","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MatrixFactorization(tf.keras.Model):\n\n    def __init__(self, num_users, num_places, embedding_size = 128, **kwargs):\n        super(MatrixFactorization, self).__init__(**kwargs)\n        \n        \"\"\" Attributes \"\"\"\n        self.num_users = num_users + 1\n        self.num_places = num_places + 1\n        self.embedding_size = embedding_size\n        \"\"\" End of Attributes \"\"\"\n        \n        \"\"\"\" Model's Layers \"\"\"\n        # Users Embedding Layer\n        self.users_embedding = tf.keras.layers.Embedding(\n            input_dim = self.num_users,\n            output_dim = self.embedding_size,\n            name = 'users_embedding',\n            embeddings_initializer = tf.keras.initializers.HeNormal(),\n            embeddings_regularizer = tf.keras.regularizers.L2(1e-6), \n            input_length=1\n        )\n        # Places Embedding Layer\n        self.places_embedding = tf.keras.layers.Embedding(\n            input_dim = self.num_places,\n            output_dim = self.embedding_size,\n            name = 'places_embedding',\n            embeddings_initializer = tf.keras.initializers.HeNormal(),\n            embeddings_regularizer = tf.keras.regularizers.L2(1e-6), \n            input_length=1\n        )\n        # Flatten Layer\n        self.flatten = tf.keras.layers.Flatten(name = 'flatten')\n        # Multiply Layer\n        self.multiply = tf.keras.layers.Multiply(name = 'multiply')\n        # Add Layer\n        self.add = tf.keras.layers.Add(name = 'add')\n        # Output Layer\n        self.out = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'out')\n        \n        \"\"\" End of Model's Layers \"\"\"\n        \n    def call(self, inputs):\n        users, places = tf.unstack(inputs, axis = 1)\n\n        # Call each embedding layer respectively\n        users = self.users_embedding(users)\n        places = self.places_embedding(places)\n\n        # Flatten those out\n        users = self.flatten(users)\n        places = self.flatten(places)\n\n        # Multiply and merge them\n        matrix = self.multiply([users, places])\n        \n        # Pass to dense output layer with sigmoid activation\n        out = self.out(matrix)\n\n        return out","metadata":{"id":"4RtYjMqt0ynD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nEMBEDDING_SIZE = 64\nEPOCHS = 150\nPREFERRED_LEARNING_RATE = 2e-3\nLOSS = tf.keras.losses.BinaryCrossentropy()\nOPTIMIZER = tf.keras.optimizers.Adam(learning_rate = PREFERRED_LEARNING_RATE)\nMETRICS = [tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.TopKCategoricalAccuracy()]","metadata":{"id":"opoop-Vj6Yt-","outputId":"7e4482ac-a60e-4306-8a16-06fb91d45d7a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adjust_learning_rate(x, y):\n    \n    model = MatrixFactorization(num_users, num_places, EMBEDDING_SIZE)\n    \n    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-6 * 10**(epoch / 20))\n    \n    # Select your optimizer\n    optimizer = 'adam'\n    \n    # Compile the model passing in the appropriate loss\n    model.compile(loss = LOSS,\n                  optimizer = 'adam', \n                  metrics = METRICS) \n    \n    history = model.fit(x, y, epochs=100, callbacks=[lr_schedule])\n    \n    return history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the training with dynamic LR\nlr_history = adjust_learning_rate(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.semilogx(lr_history.history[\"lr\"], lr_history.history[\"loss\"])\nplt.axis([1e-6, 10, 0, 10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Init\nmodel = MatrixFactorization(num_users, num_places, EMBEDDING_SIZE)\n\n# Compile the model with appropriate loss and optimizer\nmodel.compile(loss = LOSS, optimizer = OPTIMIZER, metrics = METRICS)\nmodel.build(input_shape = (None, 2,))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    x_train,\n    y_train,\n    epochs = EPOCHS,\n    validation_data = (x_val, y_val)\n)","metadata":{"id":"hc7DdMeB6mxu","outputId":"1e74f633-da35-44a6-caa9-892ae3fbd26d","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['mean_squared_error'])\nplt.plot(history.history['val_mean_squared_error'])\nplt.title('model mean_squared_error')\nplt.ylabel('mean_squared_error')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"model.evaluate(x_test, y_test, return_dict = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing","metadata":{}},{"cell_type":"code","source":"# Mengambil sample user\nuser_id = x_test.sample(1)['User_Id'].values[0]\nuser_id","metadata":{"id":"uOH0rBXBMbcB","outputId":"21f58154-d684-499d-f633-6b214024776d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"places_visited_by_user = df_tourism_rating[df_tourism_rating.User_Id == user_id]\n\nplaces_not_visited = df_tourism_with_id[~df_tourism_with_id['Place_Id'].isin(places_visited_by_user.Place_Id.values)].Place_Id.values\nplaces_not_visited = np.expand_dims(list(set(places_not_visited)), axis = 1)\n\nuser_places_array = np.hstack(\n    ([[user_id]] * len(places_not_visited), places_not_visited)\n)","metadata":{"id":"KF1t-fRp7kGo","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratings = model.predict(user_places_array).flatten()","metadata":{"id":"STWKVZNDEqMw","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_ratings_indices = ratings.argsort()[-15:][::-1]\nrecommended_place_ids = [places_not_visited[i][0] for i in top_ratings_indices]\n \nprint('{}'.format('User ' + str(user_id)))\nprint('===' * 15,'\\n')\nprint('----' * 15)\nprint('Top 10 most rated places from the user')\nprint('----' * 15)\n \ntop_place_user = (\n    places_visited_by_user.sort_values(\n        by = ['Place_Ratings'],\n        ascending=False\n    )\n    .head(10)\n    .Place_Id.values\n)\n \ndf_tourism_with_id_rows = df_tourism_with_id[df_tourism_with_id['Place_Id'].isin(top_place_user)]\nfor row in df_tourism_with_id_rows.itertuples():\n    print(row.Place_Name, ':', row.Category)\n\nprint('')\nprint('----' * 15)\nprint('Top 7 place recommendation')\nprint('----' * 15)\n \nrecommended_place = df_tourism_with_id[df_tourism_with_id['Place_Id'].isin(recommended_place_ids)]\nfor row, i in zip(recommended_place.itertuples(), range(15)):\n    print(i+1,'.',\n          row.Place_Name, '\\n   ', \n          row.Category, ',', 'Harga Tiket Masuk ', \n          row.Price, ',', 'Rating Wisata ', \n          row.Rating,'\\n'\n         )\n\nprint('==='*15)","metadata":{"id":"2d_iSBTgLPUu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_ratings_indices = ratings.argsort()[-15:][::-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/saved_model')\n!zip keras_saved_model.zip '/kaggle/working/saved_model'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new_model = tf.keras.models.load_model('/kaggle/working/saved_model')\n\nnew_model = tf.saved_model.load('/kaggle/working/saved_model')\nmodel_variables = new_model.variables\nmodel_function = new_model.signatures[\"serving_default\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# args: user_id, places_visited (Place_Id), \n\ndef predict(model, user_id, places_not_visited, n = 50):\n    \"\"\"\n    Do prediction on a single user\n    \n    Args:\n        model                : TensorFlow loaded saved_model\n        user_id              : int32,\n        place_not_visited_ids: array, \n        n                    : int32, number of predictions returned\n        \n    Returns:\n        recommended_place_ids: ndarray, containing Place_Id recommendation\n    \"\"\"\n    \n    # Create places_to_predict array by querying from tourism database\n    places_not_visited = np.expand_dims(list(set(places_not_visited)), axis = 1)\n\n    places_to_predict = np.hstack(\n        ([[user_id]] * len(places_not_visited), places_not_visited)\n    )\n    \n    # Predict\n    model_function = model.signatures[\"serving_default\"]\n    ratings = model_function(tf.constant(places_to_predict))\n    \n    # Prediction\n    top_ratings_indices = ratings.argsort()[-num_predictions:][::-1]\n    recommended_place_ids = [places_not_visited[i][0] for i in top_ratings_indices]\n    \n    return recommended_place_ids","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"places_not_visited = df_tourism_with_id[~df_tourism_with_id['Place_Id'].isin(places_visited_by_user.Place_Id.values)].Place_Id.values\n\n# predict(new_model, user_id, places_not_visited, 10)\nnew_model = tf.saved_model.load('/kaggle/working/saved_model')\n\npredict(new_model, user_id, places_not_visited, 10)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}